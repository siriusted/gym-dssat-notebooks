{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Package installation on colab",
      "provenance": [],
      "authorship_tag": "ABX9TyOmkWKTBAIF3e9ZsDKtXpPd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siriusted/gym-dssat-notebooks/blob/master/Package_installation_on_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EO6mXlZLpKH"
      },
      "outputs": [],
      "source": [
        "!echo \"deb [ arch=amd64 ] https://raw.githubusercontent.com/pdidev/repo/ubuntu bionic main\" | sudo tee /etc/apt/sources.list.d/pdi.list > /dev/null\n",
        "!wget -O /etc/apt/trusted.gpg.d/pdidev-archive-keyring.gpg https://raw.githubusercontent.com/pdidev/repo/ubuntu/pdidev-archive-keyring.gpg\n",
        "!chmod a+r /etc/apt/trusted.gpg.d/pdidev-archive-keyring.gpg /etc/apt/sources.list.d/pdi.list\n",
        "!apt update\n",
        "!apt install pdidev-archive-keyring libpdi-dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://gac.udc.es/~emilioj/bionic-dev.tgz\n",
        "!tar -xf bionic-dev.tgz\n",
        "!cd bionic-dev/ && apt install `find . -name \"*.deb\"`"
      ],
      "metadata": {
        "id": "zdKzu2AaMYsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3[extra]"
      ],
      "metadata": {
        "id": "uSyRCO333jgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/opt/gym_dssat_pdi/bin/pip uninstall seaborn stable-baselines3[extra]"
      ],
      "metadata": {
        "id": "9R6ZAwj-tu-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PATH\"] = \"/opt/gym_dssat_pdi/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"PYTHONPATH\"] = \"/opt/gym_dssat_pdi/lib/python3.6/site-packages/:\" + os.environ[\"PYTHONPATH\"]\n",
        "# os.environ[\"GYM_DSSAT_PDI_PATH\"] = \"/opt/gym_dssat_pdi/lib/python3.6/site-packages/gym_dssat_pdi\""
      ],
      "metadata": {
        "id": "gBuzyrmkPb-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "nWenhrKZPjMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/opt/gym_dssat_pdi/bin/python /opt/gym_dssat_pdi/samples/run_env.py"
      ],
      "metadata": {
        "id": "3eAy3hqhNI1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.insert(1, '/opt/gym_dssat_pdi/lib/python3.6/site-packages')"
      ],
      "metadata": {
        "id": "ex3UofeBgXTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sys.path)"
      ],
      "metadata": {
        "id": "G8amJH2MkM4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/opt/gym_dssat_pdi/bin/pip list"
      ],
      "metadata": {
        "id": "HCi_F7X9uNjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import gym_dssat_pdi\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.callbacks import EvalCallback"
      ],
      "metadata": {
        "id": "5rhldkQA-llS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_args = {\n",
        "            'run_dssat_location': '/opt/dssat_pdi/run_dssat',\n",
        "            'log_saving_path': './logs/dssat_pdi.log',\n",
        "            'mode': 'fertilization',\n",
        "            'seed': 123456,\n",
        "            'random_weather': True,\n",
        "        }\n",
        "\n",
        "env = gym.make('gym_dssat_pdi:GymDssatPdi-v0', **env_args)"
      ],
      "metadata": {
        "id": "MdPHIffPRfq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.observation"
      ],
      "metadata": {
        "id": "BsLxrIELlhSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helpers for action normalization\n",
        "def normalize_action(action_space_limits, action):\n",
        "    \"\"\"Normalize the action from [low, high] to [-1, 1]\"\"\"\n",
        "    low, high = action_space_limits\n",
        "    return 2.0 * ((action - low) / (high - low)) - 1.0\n",
        "\n",
        "def denormalize_action(action_space_limits, action):\n",
        "    \"\"\"Denormalize the action from [-1, 1] to [low, high]\"\"\"\n",
        "    low, high = action_space_limits\n",
        "    return low + (0.5 * (action + 1.0) * (high - low))\n",
        "\n",
        "# Wrapper for easy and uniform interfacing with SB3\n",
        "class GymDssatWrapper(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super(GymDssatWrapper, self).__init__(env)\n",
        "\n",
        "        self.action_low, self.action_high = self._get_action_space_bounds()\n",
        "\n",
        "        # using a normalized action space\n",
        "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=\"float32\")\n",
        "\n",
        "        # using a vector representation of observations to allow\n",
        "        # easily using SB3 MlpPolicy\n",
        "        self.observation_space = gym.spaces.Box(low=0.0,\n",
        "                                                high=np.inf,\n",
        "                                                shape=env.observation_dict_to_array(\n",
        "                                                    env.observation).shape,\n",
        "                                                dtype=\"float32\"\n",
        "                                                )\n",
        "\n",
        "        # to avoid annoying problem with Monitor when episodes end and things are None\n",
        "        self.last_info = {}\n",
        "        self.last_obs = None\n",
        "\n",
        "    def _get_action_space_bounds(self):\n",
        "        box = self.env.action_space['anfer']\n",
        "        return box.low, box.high\n",
        "\n",
        "    def _format_action(self, action):\n",
        "        return { 'anfer': action[0] }\n",
        "\n",
        "    def _format_observation(self, observation):\n",
        "        return self.env.observation_dict_to_array(observation)\n",
        "\n",
        "    def reset(self):\n",
        "        return self._format_observation(self.env.reset())\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        # Rescale action from [-1, 1] to original action space interval\n",
        "        denormalized_action = denormalize_action((self.action_low, self.action_high), action)\n",
        "        formatted_action = self._format_action(denormalized_action)\n",
        "        obs, reward, done, info = self.env.step(formatted_action)\n",
        "\n",
        "        # handle `None`s in obs, reward, and info on done step\n",
        "        if done:\n",
        "            obs, reward, info = self.last_obs, 0, self.last_info\n",
        "        else:\n",
        "            self.last_obs = obs\n",
        "            self.last_info = info\n",
        "\n",
        "        formatted_observation = self._format_observation(obs)\n",
        "        return formatted_observation, reward, done, info\n",
        "\n",
        "    def close(self):\n",
        "        return self.env.close()\n",
        "\n",
        "    def seed(self, seed):\n",
        "        self.env.set_seed(seed)\n",
        "\n",
        "    def eval(self):\n",
        "        self.env.set_evaluation()\n",
        "\n",
        "\n",
        "    def __del__(self):\n",
        "        self.close()"
      ],
      "metadata": {
        "id": "yfsS0Dgs-oh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create environment\n",
        "env_args = {\n",
        "    'run_dssat_location': '/opt/dssat_pdi/run_dssat',\n",
        "    'mode': 'fertilization',\n",
        "    'seed': 123,\n",
        "    'random_weather': True,\n",
        "}\n",
        "\n",
        "env = Monitor(GymDssatWrapper(gym.make('GymDssatPdi-v0', **env_args)))"
      ],
      "metadata": {
        "id": "EXf6-ept-uFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training arguments for PPO agent\n",
        "ppo_args = {\n",
        "    'seed': 123, # seed training for reproducibility\n",
        "}\n",
        "\n",
        "# Create the agent\n",
        "ppo_agent = PPO('MlpPolicy', env, **ppo_args)\n",
        "\n",
        "# Train for 900k timesteps\n",
        "print('Training PPO agent...')\n",
        "ppo_agent.learn(total_timesteps=900_000)\n",
        "print('Training done')"
      ],
      "metadata": {
        "id": "edY3O1g8wKrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline agents for comparison\n",
        "class NullAgent:\n",
        "    \"\"\"\n",
        "    Agent always choosing to do no fertilization\n",
        "    \"\"\"\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "\n",
        "    def predict(self, obs, state=None, episode_start=None, deterministic=None):\n",
        "        action = normalize_action((self.env.action_low, self.env.action_high), [0])\n",
        "        return np.array([action], dtype=np.float32), obs\n",
        "\n",
        "\n",
        "class ExpertAgent:\n",
        "    \"\"\"\n",
        "    Simple agent using policy of choosing fertilization amount based on days after planting\n",
        "    \"\"\"\n",
        "    fertilization_dic = {\n",
        "        40: 27,\n",
        "        45: 35,\n",
        "        80: 54,\n",
        "    }\n",
        "\n",
        "    def __init__(self, env, normalize_action=False, fertilization_dic=None):\n",
        "        self.env = env\n",
        "        self.normalize_action = normalize_action\n",
        "\n",
        "    def _policy(self, obs):\n",
        "        dap = int(obs[0][0])\n",
        "        return [self.fertilization_dic[dap] if dap in self.fertilization_dic else 0]\n",
        "\n",
        "    def predict(self, obs, state=None, episode_start=None, deterministic=None):\n",
        "        action = self._policy(obs)\n",
        "        action = normalize_action((self.env.action_low, self.env.action_high), action)\n",
        "\n",
        "        return np.array([action], dtype=np.float32), obs"
      ],
      "metadata": {
        "id": "gaTvuZpbxH0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation and plotting functions\n",
        "def evaluate(agent, n_episodes=10):\n",
        "    # Create eval env\n",
        "    eval_args = {\n",
        "        'run_dssat_location': '/opt/dssat_pdi/run_dssat',\n",
        "        'mode': 'fertilization',\n",
        "        'seed': 456,\n",
        "        'random_weather': True,\n",
        "    }\n",
        "    env = Monitor(GymDssatWrapper(gym.make('GymDssatPdi-v0', **eval_args)))\n",
        "\n",
        "    returns, _ = evaluate_policy(\n",
        "        agent, env, n_eval_episodes=n_episodes, return_episode_rewards=True)\n",
        "    \n",
        "    env.close()\n",
        "\n",
        "    return returns\n",
        "\n",
        "# evaluate agents\n",
        "null_agent = NullAgent(env)\n",
        "print('Evaluating Null agent...')\n",
        "null_returns = evaluate(null_agent)\n",
        "print('Done')\n",
        "\n",
        "print('Evaluating PPO agent...')\n",
        "ppo_returns = evaluate(ppo_agent)\n",
        "print('Done')\n",
        "\n",
        "expert_agent = ExpertAgent(env)\n",
        "print('Evaluating Expert agent...')\n",
        "expert_returns = evaluate(expert_agent)\n",
        "print('Done')\n",
        "\n",
        "# write results to a file to be loaded for display\n",
        "data = [('null', null_returns), ('ppo', ppo_returns), ('expert', expert_returns)]"
      ],
      "metadata": {
        "id": "x1WkUw5LxLJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "4xsQW0b8xqts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(data):\n",
        "    data_dict = {}\n",
        "    for label, returns in data:\n",
        "        data_dict[label] = returns\n",
        "    df = pd.DataFrame(data_dict)\n",
        "    \n",
        "    ax = sns.boxplot(data=df)\n",
        "    ax.set_xlabel(\"policy\")\n",
        "    ax.set_ylabel(\"evaluation output\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "SFrrbyS6YQrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7JZS53x5Egon"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}