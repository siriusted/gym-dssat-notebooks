{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Package installation on colab",
      "provenance": [],
      "authorship_tag": "ABX9TyNpSPobHKPLHtub4eBU/nlg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siriusted/gym-dssat-notebooks/blob/master/Package_installation_on_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0EO6mXlZLpKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae17ae2f-80f7-4de0-afea-48b55f1b9e9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-10 16:14:39--  https://raw.githubusercontent.com/pdidev/repo/ubuntu/pdidev-archive-keyring.gpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1753 (1.7K) [application/octet-stream]\n",
            "Saving to: ‘/etc/apt/trusted.gpg.d/pdidev-archive-keyring.gpg’\n",
            "\n",
            "\r          /etc/apt/   0%[                    ]       0  --.-KB/s               \r/etc/apt/trusted.gp 100%[===================>]   1.71K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-03-10 16:14:39 (19.1 MB/s) - ‘/etc/apt/trusted.gpg.d/pdidev-archive-keyring.gpg’ saved [1753/1753]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!echo \"deb [ arch=amd64 ] https://raw.githubusercontent.com/pdidev/repo/ubuntu bionic main\" | sudo tee /etc/apt/sources.list.d/pdi.list > /dev/null\n",
        "!wget -O /etc/apt/trusted.gpg.d/pdidev-archive-keyring.gpg https://raw.githubusercontent.com/pdidev/repo/ubuntu/pdidev-archive-keyring.gpg\n",
        "!chmod a+r /etc/apt/trusted.gpg.d/pdidev-archive-keyring.gpg /etc/apt/sources.list.d/pdi.list\n",
        "!apt update &> /dev/null\n",
        "!apt install pdidev-archive-keyring libpdi-dev &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget  http://gac.udc.es/~emilioj/bionic.tgz\n",
        "!tar -xf bionic.tgz\n",
        "!cd bionic/ && apt install `find . -name \"*.deb\"` &> /dev/null"
      ],
      "metadata": {
        "id": "zdKzu2AaMYsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3 &> /dev/null\n",
        "!pip install -U PyYAML &> /dev/null"
      ],
      "metadata": {
        "id": "uSyRCO333jgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "a4954908-0726-4763-9cc2-f100632a34c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.21.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.10.0+cu111)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.5)\n",
            "Requirement already satisfied: gym<0.20,>=0.17 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines3) (3.2.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym<0.20,>=0.17->stable-baselines3) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym<0.20,>=0.17->stable-baselines3) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8.1->stable-baselines3) (3.10.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines3) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->stable-baselines3) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines3) (2018.9)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 8.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyYAML\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "yaml"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PATH\"] = \"/opt/gym_dssat_pdi/bin:\" + os.environ[\"PATH\"]\n",
        "os.environ[\"PYTHONPATH\"] = \"/opt/gym_dssat_pdi/lib/python3.7/site-packages/:\" + os.environ[\"PYTHONPATH\"]\n",
        "# os.environ[\"GYM_DSSAT_PDI_PATH\"] = \"/opt/gym_dssat_pdi/lib/python3.6/site-packages/gym_dssat_pdi\""
      ],
      "metadata": {
        "id": "gBuzyrmkPb-7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "nWenhrKZPjMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452b7e5c-e3f2-4e0c-824c-8592fc2d2468"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/opt/gym_dssat_pdi/lib/python3.7/site-packages')"
      ],
      "metadata": {
        "id": "ex3UofeBgXTc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import gym_dssat_pdi\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5rhldkQA-llS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_args = {\n",
        "            'run_dssat_location': '/opt/dssat_pdi/run_dssat',\n",
        "            'mode': 'fertilization',\n",
        "            'seed': 123456,\n",
        "            'random_weather': True,\n",
        "        }\n",
        "\n",
        "env = gym.make('gym_dssat_pdi:GymDssatPdi-v0', **env_args)"
      ],
      "metadata": {
        "id": "MdPHIffPRfq2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.observation"
      ],
      "metadata": {
        "id": "BsLxrIELlhSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97be0f15-78dd-49ad-b919-01055e073ec6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dap': 4377089,\n",
              " 'dtt': 0.0,\n",
              " 'grnwt': 0.0,\n",
              " 'istage': 7,\n",
              " 'nstres': 0.0,\n",
              " 'pltpop': 7.199999809265137,\n",
              " 'rain': 0.10000000149011612,\n",
              " 'rtdep': 0.0,\n",
              " 'srad': 8.652971267700195,\n",
              " 'swfac': 0.0,\n",
              " 'tmax': 18.56235122680664,\n",
              " 'tmin': 6.544256687164307,\n",
              " 'topwt': 0.0,\n",
              " 'totaml': 0.0,\n",
              " 'vstage': 0.0,\n",
              " 'xlai': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "ThofkNPSobap"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helpers for action normalization\n",
        "def normalize_action(action_space_limits, action):\n",
        "    \"\"\"Normalize the action from [low, high] to [-1, 1]\"\"\"\n",
        "    low, high = action_space_limits\n",
        "    return 2.0 * ((action - low) / (high - low)) - 1.0\n",
        "\n",
        "def denormalize_action(action_space_limits, action):\n",
        "    \"\"\"Denormalize the action from [-1, 1] to [low, high]\"\"\"\n",
        "    low, high = action_space_limits\n",
        "    return low + (0.5 * (action + 1.0) * (high - low))\n",
        "\n",
        "# Wrapper for easy and uniform interfacing with SB3\n",
        "class GymDssatWrapper(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super(GymDssatWrapper, self).__init__(env)\n",
        "\n",
        "        self.action_low, self.action_high = self._get_action_space_bounds()\n",
        "\n",
        "        # using a normalized action space\n",
        "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=\"float32\")\n",
        "\n",
        "        # using a vector representation of observations to allow\n",
        "        # easily using SB3 MlpPolicy\n",
        "        self.observation_space = gym.spaces.Box(low=0.0,\n",
        "                                                high=np.inf,\n",
        "                                                shape=env.observation_dict_to_array(\n",
        "                                                    env.observation).shape,\n",
        "                                                dtype=\"float32\"\n",
        "                                                )\n",
        "\n",
        "        # to avoid annoying problem with Monitor when episodes end and things are None\n",
        "        self.last_info = {}\n",
        "        self.last_obs = None\n",
        "\n",
        "    def _get_action_space_bounds(self):\n",
        "        box = self.env.action_space['anfer']\n",
        "        return box.low, box.high\n",
        "\n",
        "    def _format_action(self, action):\n",
        "        return { 'anfer': action[0] }\n",
        "\n",
        "    def _format_observation(self, observation):\n",
        "        return self.env.observation_dict_to_array(observation)\n",
        "\n",
        "    def reset(self):\n",
        "        return self._format_observation(self.env.reset())\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        # Rescale action from [-1, 1] to original action space interval\n",
        "        denormalized_action = denormalize_action((self.action_low, self.action_high), action)\n",
        "        formatted_action = self._format_action(denormalized_action)\n",
        "        obs, reward, done, info = self.env.step(formatted_action)\n",
        "\n",
        "        # handle `None`s in obs, reward, and info on done step\n",
        "        if done:\n",
        "            obs, reward, info = self.last_obs, 0, self.last_info\n",
        "        else:\n",
        "            self.last_obs = obs\n",
        "            self.last_info = info\n",
        "\n",
        "        formatted_observation = self._format_observation(obs)\n",
        "        return formatted_observation, reward, done, info\n",
        "\n",
        "    def close(self):\n",
        "        return self.env.close()\n",
        "\n",
        "    def eval(self):\n",
        "        self.env.set_evaluation()\n",
        "\n",
        "    def __del__(self):\n",
        "        self.close()"
      ],
      "metadata": {
        "id": "yfsS0Dgs-oh9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "# Create environment\n",
        "env_args = {\n",
        "    'run_dssat_location': '/opt/dssat_pdi/run_dssat',\n",
        "    'mode': 'fertilization',\n",
        "    'seed': 123,\n",
        "    'random_weather': True,\n",
        "}\n",
        "\n",
        "env = Monitor(GymDssatWrapper(gym.make('GymDssatPdi-v0', **env_args)))"
      ],
      "metadata": {
        "id": "EXf6-ept-uFA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training arguments for PPO agent\n",
        "ppo_args = {\n",
        "    'seed': 123, # seed training for reproducibility\n",
        "}\n",
        "\n",
        "# Create the agent\n",
        "ppo_agent = PPO('MlpPolicy', env, **ppo_args)\n",
        "\n",
        "# Train for 10k timesteps\n",
        "print('Training PPO agent...')\n",
        "ppo_agent.learn(total_timesteps=40_000)\n",
        "print('Training done')"
      ],
      "metadata": {
        "id": "edY3O1g8wKrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae1771fc-17ac-45e1-e422-36b6b1a46c42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PPO agent...\n",
            "Training done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline agents for comparison\n",
        "class NullAgent:\n",
        "    \"\"\"\n",
        "    Agent always choosing to do no fertilization\n",
        "    \"\"\"\n",
        "    def __init__(self, env):\n",
        "        self.env = env\n",
        "\n",
        "    def predict(self, obs, state=None, episode_start=None, deterministic=None):\n",
        "        action = normalize_action((self.env.action_low, self.env.action_high), [0])\n",
        "        return np.array([action], dtype=np.float32), obs\n",
        "\n",
        "\n",
        "class ExpertAgent:\n",
        "    \"\"\"\n",
        "    Simple agent using policy of choosing fertilization amount based on days after planting\n",
        "    \"\"\"\n",
        "    fertilization_dic = {\n",
        "        40: 27,\n",
        "        45: 35,\n",
        "        80: 54,\n",
        "    }\n",
        "\n",
        "    def __init__(self, env, normalize_action=False, fertilization_dic=None):\n",
        "        self.env = env\n",
        "        self.normalize_action = normalize_action\n",
        "\n",
        "    def _policy(self, obs):\n",
        "        dap = int(obs[0][0])\n",
        "        return [self.fertilization_dic[dap] if dap in self.fertilization_dic else 0]\n",
        "\n",
        "    def predict(self, obs, state=None, episode_start=None, deterministic=None):\n",
        "        action = self._policy(obs)\n",
        "        action = normalize_action((self.env.action_low, self.env.action_high), action)\n",
        "\n",
        "        return np.array([action], dtype=np.float32), obs"
      ],
      "metadata": {
        "id": "gaTvuZpbxH0b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "#evaluation and plotting functions\n",
        "def evaluate(agent, n_episodes=10):\n",
        "    # Create eval env\n",
        "    eval_args = {\n",
        "        'run_dssat_location': '/opt/dssat_pdi/run_dssat',\n",
        "        'mode': 'fertilization',\n",
        "        'seed': 456,\n",
        "        'random_weather': True,\n",
        "    }\n",
        "    env = Monitor(GymDssatWrapper(gym.make('GymDssatPdi-v0', **eval_args)))\n",
        "\n",
        "    env.eval()\n",
        "\n",
        "    returns, _ = evaluate_policy(\n",
        "        agent, env, n_eval_episodes=n_episodes, return_episode_rewards=True)\n",
        "    \n",
        "    env.close()\n",
        "\n",
        "    return returns\n",
        "\n",
        "# evaluate agents\n",
        "null_agent = NullAgent(env)\n",
        "print('Evaluating Null agent...')\n",
        "null_returns = evaluate(null_agent)\n",
        "print('Done')\n",
        "print('Evaluating PPO agent...')\n",
        "ppo_returns = evaluate(ppo_agent)\n",
        "print('Done')\n",
        "\n",
        "expert_agent = ExpertAgent(env)\n",
        "print('Evaluating Expert agent...')\n",
        "expert_returns = evaluate(expert_agent)\n",
        "print('Done')\n",
        "\n",
        "# write results to a file to be loaded for display\n",
        "data = [('null', null_returns), ('ppo', ppo_returns), ('expert', expert_returns)]"
      ],
      "metadata": {
        "id": "x1WkUw5LxLJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95fbc00-f4b9-4221-b638-e21bbf1df871"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Null agent...\n",
            "Done\n",
            "Evaluating PPO agent...\n",
            "Done\n",
            "Evaluating Expert agent...\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "id": "4xsQW0b8xqts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_results(data):\n",
        "    data_dict = {}\n",
        "    for label, returns in data:\n",
        "        data_dict[label] = returns\n",
        "    df = pd.DataFrame(data_dict)\n",
        "    \n",
        "    ax = sns.boxplot(data=df)\n",
        "    ax.set_xlabel(\"policy\")\n",
        "    ax.set_ylabel(\"evaluation output\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SFrrbyS6YQrX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "YiB1_okJ6Ka0",
        "outputId": "919f79a4-9253-49ab-e955-1e1201089877"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus: Saving best performing model\n",
        "\n",
        "In this section, we will use a feature from stable-baselines3 known as `callbacks`. They enable different kind of operations during the training of a model. For our purpose here, we will use the `EvalCallback` to periodically evaluate and save the best performing model we find during training.\n",
        "\n",
        "For more on callbacks in stable-baselines3 see [here](https://stable-baselines3.readthedocs.io/en/master/guide/callbacks.html)"
      ],
      "metadata": {
        "id": "xRJsLed7jU0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "env = Monitor(GymDssatWrapper(gym.make('GymDssatPdi-v0', **env_args)))\n",
        "\n",
        "\n",
        "# Create the agent\n",
        "ppo_agent = PPO('MlpPolicy', env, **ppo_args)\n",
        "\n",
        "# path to save best model found\n",
        "path = 'ppo'\n",
        "\n",
        "# eval callback\n",
        "eval_freq = 1000\n",
        "eval_env_args = {**env_args, 'seed': 345}\n",
        "eval_env = Monitor(GymDssatWrapper(gym.make('GymDssatPdi-v0', **eval_env_args)))\n",
        "eval_callback = EvalCallback(eval_env,\n",
        "                                eval_freq=eval_freq,\n",
        "                                best_model_save_path=f'./{path}',\n",
        "                                deterministic=True)\n",
        "\n",
        "\n",
        "# Train\n",
        "print('Training PPO agent...')\n",
        "ppo_agent.learn(total_timesteps=50_000, callback=eval_callback)\n",
        "ppo_agent.save(f'./{path}/final_model')\n",
        "print('Training done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbOvVk-WFte6",
        "outputId": "44ebaecf-ad65-4d7f-e4bf-a420df934552"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training PPO agent...\n",
            "Eval num_timesteps=1000, episode_reward=-8572.75 +/- 2094.55\n",
            "Episode length: 153.40 +/- 2.42\n",
            "New best mean reward!\n",
            "Eval num_timesteps=2000, episode_reward=-8757.15 +/- 1849.20\n",
            "Episode length: 156.60 +/- 2.33\n",
            "Eval num_timesteps=3000, episode_reward=-7420.59 +/- 1541.66\n",
            "Episode length: 156.20 +/- 1.47\n",
            "New best mean reward!\n",
            "Eval num_timesteps=4000, episode_reward=-7275.33 +/- 1375.06\n",
            "Episode length: 158.20 +/- 1.47\n",
            "New best mean reward!\n",
            "Eval num_timesteps=5000, episode_reward=-5932.76 +/- 1409.70\n",
            "Episode length: 156.00 +/- 6.42\n",
            "New best mean reward!\n",
            "Eval num_timesteps=6000, episode_reward=-5485.42 +/- 385.85\n",
            "Episode length: 158.40 +/- 2.65\n",
            "New best mean reward!\n",
            "Eval num_timesteps=7000, episode_reward=-5259.26 +/- 1081.93\n",
            "Episode length: 156.60 +/- 1.62\n",
            "New best mean reward!\n",
            "Eval num_timesteps=8000, episode_reward=-5101.42 +/- 1905.51\n",
            "Episode length: 154.40 +/- 4.72\n",
            "New best mean reward!\n",
            "Eval num_timesteps=9000, episode_reward=-3558.30 +/- 581.78\n",
            "Episode length: 155.20 +/- 5.42\n",
            "New best mean reward!\n",
            "Eval num_timesteps=10000, episode_reward=-4007.84 +/- 527.86\n",
            "Episode length: 154.20 +/- 2.48\n",
            "Eval num_timesteps=11000, episode_reward=-2874.74 +/- 715.74\n",
            "Episode length: 157.00 +/- 5.48\n",
            "New best mean reward!\n",
            "Eval num_timesteps=12000, episode_reward=-3263.15 +/- 826.63\n",
            "Episode length: 159.80 +/- 3.54\n",
            "Eval num_timesteps=13000, episode_reward=-2669.57 +/- 1092.00\n",
            "Episode length: 157.60 +/- 4.50\n",
            "New best mean reward!\n",
            "Eval num_timesteps=14000, episode_reward=-2602.03 +/- 799.36\n",
            "Episode length: 155.40 +/- 2.87\n",
            "New best mean reward!\n",
            "Eval num_timesteps=15000, episode_reward=-1200.34 +/- 155.62\n",
            "Episode length: 154.40 +/- 2.65\n",
            "New best mean reward!\n",
            "Eval num_timesteps=16000, episode_reward=-1430.53 +/- 314.83\n",
            "Episode length: 158.40 +/- 3.38\n",
            "Eval num_timesteps=17000, episode_reward=-1015.99 +/- 144.96\n",
            "Episode length: 159.20 +/- 2.93\n",
            "New best mean reward!\n",
            "Eval num_timesteps=18000, episode_reward=-971.91 +/- 207.00\n",
            "Episode length: 158.20 +/- 3.43\n",
            "New best mean reward!\n",
            "Eval num_timesteps=19000, episode_reward=-397.48 +/- 69.40\n",
            "Episode length: 157.20 +/- 2.04\n",
            "New best mean reward!\n",
            "Eval num_timesteps=20000, episode_reward=-409.22 +/- 135.13\n",
            "Episode length: 159.00 +/- 3.85\n",
            "Eval num_timesteps=21000, episode_reward=-199.40 +/- 118.67\n",
            "Episode length: 155.40 +/- 1.74\n",
            "New best mean reward!\n",
            "Eval num_timesteps=22000, episode_reward=-214.89 +/- 41.78\n",
            "Episode length: 159.00 +/- 3.16\n",
            "Eval num_timesteps=23000, episode_reward=-133.75 +/- 23.52\n",
            "Episode length: 157.80 +/- 3.06\n",
            "New best mean reward!\n",
            "Eval num_timesteps=24000, episode_reward=-148.52 +/- 25.89\n",
            "Episode length: 161.20 +/- 3.76\n",
            "Eval num_timesteps=25000, episode_reward=-27.62 +/- 27.93\n",
            "Episode length: 158.00 +/- 2.28\n",
            "New best mean reward!\n",
            "Eval num_timesteps=26000, episode_reward=-52.82 +/- 27.97\n",
            "Episode length: 156.80 +/- 4.75\n",
            "Eval num_timesteps=27000, episode_reward=28.20 +/- 13.79\n",
            "Episode length: 156.80 +/- 3.19\n",
            "New best mean reward!\n",
            "Eval num_timesteps=28000, episode_reward=-1.50 +/- 36.81\n",
            "Episode length: 152.60 +/- 4.63\n",
            "Eval num_timesteps=29000, episode_reward=22.23 +/- 13.78\n",
            "Episode length: 160.00 +/- 2.19\n",
            "Eval num_timesteps=30000, episode_reward=25.43 +/- 12.03\n",
            "Episode length: 158.60 +/- 5.54\n",
            "Eval num_timesteps=31000, episode_reward=28.23 +/- 9.49\n",
            "Episode length: 158.20 +/- 1.33\n",
            "New best mean reward!\n",
            "Eval num_timesteps=32000, episode_reward=31.25 +/- 11.90\n",
            "Episode length: 158.40 +/- 1.36\n",
            "New best mean reward!\n",
            "Eval num_timesteps=33000, episode_reward=32.63 +/- 17.59\n",
            "Episode length: 156.80 +/- 3.82\n",
            "New best mean reward!\n",
            "Eval num_timesteps=34000, episode_reward=21.96 +/- 12.08\n",
            "Episode length: 154.20 +/- 3.76\n",
            "Eval num_timesteps=35000, episode_reward=33.30 +/- 7.19\n",
            "Episode length: 157.00 +/- 2.53\n",
            "New best mean reward!\n",
            "Eval num_timesteps=36000, episode_reward=23.07 +/- 6.97\n",
            "Episode length: 158.40 +/- 2.65\n",
            "Eval num_timesteps=37000, episode_reward=38.25 +/- 6.15\n",
            "Episode length: 158.60 +/- 5.43\n",
            "New best mean reward!\n",
            "Eval num_timesteps=38000, episode_reward=28.42 +/- 12.16\n",
            "Episode length: 156.60 +/- 1.85\n",
            "Eval num_timesteps=39000, episode_reward=21.02 +/- 15.83\n",
            "Episode length: 158.60 +/- 4.63\n",
            "Eval num_timesteps=40000, episode_reward=17.34 +/- 9.79\n",
            "Episode length: 156.40 +/- 3.38\n",
            "Eval num_timesteps=41000, episode_reward=23.62 +/- 7.81\n",
            "Episode length: 155.00 +/- 3.29\n",
            "Eval num_timesteps=42000, episode_reward=33.70 +/- 7.95\n",
            "Episode length: 152.80 +/- 2.32\n",
            "Eval num_timesteps=43000, episode_reward=27.11 +/- 9.96\n",
            "Episode length: 157.20 +/- 2.32\n",
            "Eval num_timesteps=44000, episode_reward=15.38 +/- 14.93\n",
            "Episode length: 138.60 +/- 44.23\n",
            "Eval num_timesteps=45000, episode_reward=26.47 +/- 5.66\n",
            "Episode length: 160.00 +/- 2.53\n",
            "Eval num_timesteps=46000, episode_reward=33.06 +/- 17.89\n",
            "Episode length: 156.00 +/- 3.63\n",
            "Eval num_timesteps=47000, episode_reward=27.39 +/- 9.15\n",
            "Episode length: 156.20 +/- 3.19\n",
            "Eval num_timesteps=48000, episode_reward=27.41 +/- 4.94\n",
            "Episode length: 156.20 +/- 4.40\n",
            "Eval num_timesteps=49000, episode_reward=32.08 +/- 4.92\n",
            "Episode length: 157.80 +/- 4.71\n",
            "Eval num_timesteps=50000, episode_reward=26.51 +/- 6.71\n",
            "Episode length: 158.00 +/- 6.00\n",
            "Eval num_timesteps=51000, episode_reward=42.26 +/- 1.16\n",
            "Episode length: 157.60 +/- 2.58\n",
            "New best mean reward!\n",
            "Training done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate agents\n",
        "null_agent = NullAgent(env)\n",
        "print('Evaluating Null agent...')\n",
        "null_returns = evaluate(null_agent)\n",
        "print('Done')\n",
        "\n",
        "print('Evaluating PPO agents...')\n",
        "ppo_best = PPO.load(f'./{path}/best_model')\n",
        "ppo_best_returns = evaluate(ppo_best)\n",
        "ppo_returns = evaluate(ppo_agent)\n",
        "print('Done')\n",
        "\n",
        "expert_agent = ExpertAgent(env)\n",
        "print('Evaluating Expert agent...')\n",
        "expert_returns = evaluate(expert_agent)\n",
        "print('Done')\n",
        "\n",
        "# write results to a file to be loaded for display\n",
        "results = [('null', null_returns), ('ppo(best)', ppo_best_returns),  ('ppo(final)', ppo_returns), ('expert', expert_returns)]"
      ],
      "metadata": {
        "id": "RnQHnRq1tUFf",
        "outputId": "54f104dc-b2ad-4a4f-8213-4d5a6f8f105b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Null agent...\n",
            "Done\n",
            "Evaluating PPO agents...\n",
            "Done\n",
            "Evaluating Expert agent...\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(results)"
      ],
      "metadata": {
        "id": "UZxMsJCft2U8",
        "outputId": "18c2e58f-db35-4a2d-d52d-9174e043d378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAauElEQVR4nO3de5hdVZnn8e8vF0wAMUAi0ClCkAoqMKhYcmkcG4giIDZMS3NpBgPSk2llCMqoBK/9MDqC2ioFKkaxKZAGhdGGsUHJcPXCLSGRW4gpIIHiCZAggQBBEvLOH3sVHGufquzUObv2qarf53nqOXuvvc9ab62c1Hv2Za2tiMDMzKzWmKoDMDOz1uPkYGZmOU4OZmaW4+RgZmY5Tg5mZpYzruoAmmHy5Mkxffr0qsMwMxtWFi5cuDoiptTbNiKSw/Tp01mwYEHVYZiZDSuSVvS3zaeVzMwsx8nBzMxynBzMzCzHycHMzHKcHMzMLMfJwczMckpPDpJ+LOlpSffXlG0nab6kZel121QuSZ2SuiXdK2mfsuMzM7O8oRjncAlwIXBpTdlc4MaIOFfS3LR+FnA4MCP97Ad8P72amZWus7OT7u7uhuro6ekBoK2traF62tvbmTNnTkN1NKL0I4eIuA34U5/io4CutNwFHF1Tfmlk7gAmSdqp7BjNzJpl3bp1rFu3ruowGlbVCOkdImJlWn4S2CEtTwUer9mvJ5WtpA9Js4HZANOmTSsvUjMbNZrxTb23js7OzobrqlLlF6QjexTdZj+OLiLmRURHRHRMmVJ3ahAzMxukqpLDU72ni9Lr06n8CWDnmv3aUpmZmQ2hqpLDtcCstDwLuKam/KPprqX9gedqTj+ZmdkQKf2ag6QrgIOAyZJ6gC8D5wI/k3QqsAI4Nu1+HXAE0A28BJxSdnxmZpZXenKIiBP62TSzzr4BnFZuRGZmtimVX5A2M7PW4+RgZmY5Tg5mZpbj5GBmZjlODmZmluPkYGZmOU4OZmaW4+RgZmY5Tg5mZpbj5GBmZjlODmZmluPkYGZmOU4OZmaW4+RgZmY5Tg5mZpbj5GBmZjlODmZmluPkYGZmOU4OZmaW4+RgZmY5Tg5mZpbj5GBmZjmVJgdJn5L0gKT7JV0haYKkXSXdKalb0k8lbVFljGZmo1FlyUHSVGAO0BERewFjgeOB84BvR0Q78CxwalUxmpmNVlWfVhoHTJQ0DtgSWAkcAlydtncBR1cUm5nZqFVZcoiIJ4BvAo+RJYXngIXAmojYkHbrAabWe7+k2ZIWSFqwatWqoQjZzGzUqPK00rbAUcCuwF8BWwGHFX1/RMyLiI6I6JgyZUpJUZqZjU5VnlZ6P/BoRKyKiPXAz4EDgUnpNBNAG/BEVQGamY1WVSaHx4D9JW0pScBM4EHgZuCYtM8s4JqK4jMzG7WqvOZwJ9mF53uA+1Is84CzgDMldQPbAxdXFaOZ2Wg1btO7lCcivgx8uU/xI8C+FYRjZmZJ1beymplZC3JyMDOzHCcHMzPLcXIwM7McJwczM8txcjAzsxwnBzMzy3FyMDOzHCcHMzPLcXIwM7McJwczM8txcjAzsxwnBzMzy3FyMDOzHCcHMzPLcXIwM7McJwczM8txcjAzs5xNJgdJBxYpMzOzkaPIkcMFBcvMzGyEGNffBkkHAH8NTJF0Zs2mbYCxZQdmZmbVGejIYQtga7IE8saan+eBY5rRuKRJkq6W9JCkJZIOkLSdpPmSlqXXbZvRlpmZFdfvkUNE3ArcKumSiFhRUvvnA7+KiGMkbQFsCXwOuDEizpU0F5gLnFVS+2ZmVke/yaHGJZKib2FEHNJIw5LeBLwPODnV9wrwiqSjgIPSbl3ALTg5mJkNqSLJ4dM1yxOAjwAbmtD2rsAq4F8lvQNYCJwB7BARK9M+TwI71HuzpNnAbIBp06Y1IRwzM+u1yeQQEQv7FP1O0l1Nansf4PSIuFPS+WSnkGrbjnpHLWnbPGAeQEdHR919zMxscIqMc9iu5meypA8Cb2pC2z1AT0TcmdavJksWT0naKbW9E/B0E9oyM7PNUOS00kIgAJGdTnoUOLXRhiPiSUmPS3prRCwFZgIPpp9ZwLnp9ZpG2zKz0aGzs5Pu7u5KY1i2bBkAc+bMqTQOgPb29kHHUeS00q6DqrmY04HL051KjwCnkB3N/EzSqcAK4NgS2zezEaS7u5uHFi9mxwpj6D0ds2bx4gqjyC7YNmKTyUHSBOATwHvJjiB+A1wUES832DYRsRjoqLNpZqN1m9notCNwKqo6jMpdTGOXYoucVroUWMvrU2b8A3AZ8PcNtWxmZi2rSHLYKyL2qFm/WdKDZQVkZmbVKzLx3j2S9u9dkbQfsKC8kMzMrGpFjhzeDfxe0mNpfRqwVNJ9ZEMR9i4tOjMzq0SR5HBY6VGYmVlLKZIcvhIRJ9UWSLqsb5mZmY0cRa457Fm7Imkc2akmMzMbofpNDpLOlrQW2FvS85LWpvWn8KhlM7MRbaDnOXwN+Jqkr0XE2UMYU8tpxpD8np4eANra2hqqp5Hh8K2iVfpzJPQlNN6f/mxaPUWuOVwv6X19CyPithLiGbHWrVtXdQgjivuzedyXVk+R5PCZmuUJwL5kk/E19LCf4aQZ34Z66+js7Gy4ruHO/dlcjfan+9LqKTLx3odr1yXtDHyntIjMzKxyRe5W6qsHeHuzAzEzs9ZRZFbWC+C16f3GAO8E7ikzKDMzq1aRaw618yhtAK6IiN+VFI+Z2aD19PSwlsanqx4JVgIvpDvRBqPINYeu9DCe3VPR0kG3ZmZmw0KR00oHAV3AcrJHhe4saZZvZTWzVtPW1saa1av9sB+yo6dJDYxdKXJa6V+AQ9NznpG0O3AFnkLDzGzEKnK30vjexAAQEX8ExpcXkpmZVa3QBWlJPwJ+ktZPxA/7MTMb0Yokh48DpwG9wzB/A3yvtIjMzKxyRe5W+jPwrfTTdJLGkh2JPBERR0raFbgS2J5smo6TIuKVMto2M7P6BjNCutnOAJbUrJ8HfDsi2oFngVMricrMbBSrNDlIagM+BPworYtsQr+r0y5dwNHVRGdmNnpVfeTwHeCzwMa0vj2wJiI2pPUeYGq9N0qaLWmBpAWrVq0qP1Izs1GkyCC43cmm7d6ldv+IaGjKbklHAk9HxMI00G6zRMQ8YB5AR0eHx8qbmTVRkbuVrgIuAn4IvNrEtg8E/lbSEWTPidgGOB+YJGlcOnpoA55oYptmZlZAkeSwISK+3+yG06NHz4bXpuj4dEScKOkq4BiyO5Zm4edVm5kNuSLXHP6vpE9I2knSdr0/JcZ0FnCmpG6yaxAXl9iWmZnVUeTIYVZ6rX1caABvaVYQEXELcEtafoTsUaRmZlaRIoPgdh2KQMzMrHUUuVtpPNkUGu9LRbcAP4iI9SXGZWZmFSpyWun7ZLOw9s6ndFIq+8eygjIzs2oVSQ7viYh31KzfJOkPZQVkZmbVK5IcXpW0W0Q8DCDpLTR3vEPpOjs76e7urjSGZcuWATBnzpxN7Fm+9vb2QcfRCn0JrdOfjfQltEZ/tkpfQuP9ac1TJDl8BrhZ0iNkjwndBTil1KiarLu7m0X3PcjGLcu8A3dgeiUbxL3w4ScriwFgzEt/auj93d3d/PH+e5i2dbXfD7ZYn92F/fLyuyuL4bEXxjZcR3d3N4seWASTmhDQYKXJaxY9sajCIIA11TZvf6nI3Uo3SpoBvDUVLU3TeA8rG7fcjpf3OLLqMCo34cFfNlzHtK1f5QsdLzQhmuHtKwu2bk5Fk2DjQRs3vd8IN+aWqqd6s1r9JgdJh0TETZL+rs+mdklExM9Ljs3MzCoy0JHD3wA3AR+usy0AJwczsxGq3+QQEV9Oi+dExKO129LT2szMbIQqcpLv/9Qpu7pOmZmZjRADXXN4G7An8KY+1x22IZti28zMRqiBrjm8FTiS7Ca72usOa4H/VmZQZmZWrYGuOVwDXCPpgIi4fQhjarqenh7GvPRcU27jHO7GvPQMPT0bNr1jP3p6enhx7djm3cY5jK1YO5atenoaqqOnpwee822cAKyBnmisPwGeBC6muodDPpNet68sgsyTNDZ8psgguEWSTiM7xfTa6aSI+FgD7ZqZNV17e3vVIbAqjTifNGNGpXFMorH+KJIcLgMeAj4InAOcCCwZdIsVaGtr46k/j/MgOLJBcG1tOw76/W1tbby8YaUHwZENgpvQ1tZQHW1tbazSKg+CIzt6apvaWH+2wtQbvTF0dnZWHEljihzLtkfEF4EXI6IL+BCwX7lhmZlZlYokh97nNqyRtBfwJuDN5YVkZmZVK3JaaZ6kbYEvAtcCWwNfKjUqMzOrVJGJ936UFm+lic+NNjOz1lXkMaF1jxIi4pzmh2NmZq2gyGmlF2uWJ5ANjBtWdyuZmdnmKXJa6V9q1yV9E/h1ow1L2hm4FNiBbJbXeRFxvqTtgJ8C04HlwLER8Wyj7ZmZWXFFjhz62hJo7GbkzAbgf0bEPZLeCCyUNB84GbgxIs6VNBeYC5zVaGNjXvpTpSOk9fLzAMSEbSqLAXqfBDf4cQ6QPQGt6hHST72U3Wi3w5bVjQ947IWx7N6MitZUPEK6d8hK1YPe1wBTK47BXlPkmsN98NpY9LHAFLLBcA2JiJXAyrS8VtISso/GUcBBabcu4BYaTA6tMGpy2bK1AMzYrbE/zI3bsaH+aIW+BHgljUKdML26Uai703h/tEJ/9j5DesbUakf0MrU1+sMyihh4DhJJu9SsbgCeiojBT85Tv43pwG3AXsBjETEplQt4tne9z3tmA7MBpk2b9u4VK1Y0M6SmGymjJluF+7N53JfNNZz6U9LCiOiot63fY1lJ26Xz/2trftYB26TyZgW3NdkzIz4ZEc/Xbossc9XNXhExLyI6IqJjypQpzQrHzMwY+LTSQrI/zKqzLWjCmAdJ48kSw+U1z6R+StJOEbFS0k7A0422Y2Zmm2egKbtLfRRoOmV0MbAkIr5Vs+laYBZwbnq9psw4zMwsr9DdSmn6jBn85ZTdtzXY9oHAScB9khanss+RJYWfSToVWAEc22A7Devs7KS7u7uhOnov+jU6a2R7e3tLzDzZiFbpz5HQl9B4f/qzafUUuVvpH4EzyG5fXQzsD9wOHNJIwxHxW+qfsgKY2UjdrWjixIlVhzCiuD+bx31p9RQ5cjgDeA9wR0QcnJ4t/b/LDau1+NtQc7k/m8v9aWUoMvLm5Yh4GUDSGyLiIbLnS5uZ2QhV5MihR9Ik4N+B+ZKeJbsWYGZmI1SRuZX+S1r8Z0k3kz3s51elRmVmZpUqckG6E7gyIn4fEbcOQUxmZlaxItccFgJfkPSwpG9KqjvU2szMRo5NJoeI6IqII8juWFoKnCdpWemRmZlZZTZnnuB24G3ALsBD5YRjZmatYJPJQdLX05HCOcB9QEdEfLj0yMzMrDJFbmV9GDggIlaXHYyZmbWGIqeVfggcJulLAJKmSdq33LDMzKxKRZLDd4EDgBPS+tpUZmZmI1SR00r7RcQ+khYBRMSzkrYoOS4zM6tQkSOH9ZLGkp7IJmkKUN1T3c3MrHRFkkMn8AvgzZK+CvyWUTYrq5nZaFNkbqXLJS0ke8aCgKMjYknpkZmZWWUKPQkuTdPtgW9mZqPE5oyQNjOzUcLJwczMcpwczMwsx8nBzMxyWjY5SDpM0lJJ3ZLmVh2Pmdlo0pLJIQ26+y5wOLAHcIKkPaqNysxs9GjJ5ADsC3RHxCMR8QpwJXBUxTGZmY0arZocpgKP16z3pLLXSJotaYGkBatWrRrS4MzMRrpWTQ6bFBHzIqIjIjqmTJlSdThmZiNKoRHSFXgC2LlmvS2VmZmVprOzk+7u7obqWLZsGQBz5sxpqJ729vaG62hEqx453A3MkLRrmh78eODaimMyM9ukiRMnMnHixKrDaFhLHjlExAZJ/wP4NTAW+HFEPFBxWGY2wlX5Tb3VtGRyAIiI64Drqo7DzGw0atXTSmZmViEnBzMzy3FyMDOzHCcHMzPLcXIwM7McJwczM8txcjAzsxwnBzMzy3FyMDOzHCcHMzPLcXIwM7McJwczM8txcjAzsxwnBzMzy3FyMDOzHCcHMzPLcXIwM7McJwczM8txcjAzsxwnBzMzy3FyMDOznEqSg6RvSHpI0r2SfiFpUs22syV1S1oq6YNVxGdmNtpVdeQwH9grIvYG/gicDSBpD+B4YE/gMOB7ksZWFKOZ2ahVSXKIiBsiYkNavQNoS8tHAVdGxJ8j4lGgG9i3ihjNzEazVrjm8DHg+rQ8FXi8ZltPKjMzsyE0rqyKJf0/YMc6mz4fEdekfT4PbAAuH0T9s4HZANOmTWsgUjMz66u05BAR7x9ou6STgSOBmRERqfgJYOea3dpSWb365wHzADo6OqLePmZmNjhV3a10GPBZ4G8j4qWaTdcCx0t6g6RdgRnAXVXEaGY2mpV25LAJFwJvAOZLArgjIv4pIh6Q9DPgQbLTTadFxKsVxWhmNmpVkhwion2AbV8FvjqE4ZiZWR+tcLeSmZm1GCcHMzPLcXIwM7McJwczM8txcjAzsxwnBzOzJlq9ejWnn346zzzzTNWhNMTJwcysibq6urj33nvp6uqqOpSGODmYmTXJ6tWruf7664kIrr/++mF99ODkYGbWJF1dXfROFbdx48ZhffTg5GBm1iTz589n/fr1AKxfv54bbrih4ogGz8nBzKxJPvCBDzB+/HgAxo8fz6GHHlpxRIPn5GBm1iSzZs0iTSbKmDFjmDVrVsURDZ6Tg5lZk0yePJnDDz8cSRx++OFsv/32VYc0aFVN2W1mNiLNmjWL5cuXD+ujBnByMDNrqsmTJ3PBBRdUHUbDfFrJzMxynBzMzCzHycHMzHKcHMzMLEe9Q72HM0mrgBVVx1HAZGB11UGMIO7P5nFfNtdw6c9dImJKvQ0jIjkMF5IWRERH1XGMFO7P5nFfNtdI6E+fVjIzsxwnBzMzy3FyGFrzqg5ghHF/No/7srmGfX/6moOZmeX4yMHMzHKcHMzMLMfJoUKSDpL0y7R8sqQLq46plUn6pKSPpuVbJDV0q6CkSZI+UbM+RdKvGo1zOOjTl2+TtFjSIkm7Sfp9A/VeIumYtHylpBnNinmkS38D/qrqOHo5OdiwIGkc8DHg35pY7STgteQQEauAlZIObGIbLadOXx4NXB0R74qIhyPir5vU1PeBzzaprhFN0ljgZMDJYSSSNF3SEkk/lPSApBskTaz9litpsqTlFYc6ZFKfPCTp8tQ3V0vaUtJySV+XdJ+kuyS11+x/k6R7Jd0oaVqq6hDgnojYUFP9Sekb7/2S9k3v30rSj1OdiyQdlcr3TGWLU90zgHOB3VLZN1Kd/w6cOCSds5nK6EtJRwCfBD4u6eb0vhfS60Hps3t1TbtK274k6e7U9/N6y/v4DfD+lIyGJUn/teZz8wNJ+6X+nJA+aw9I2iv11W2S/kPSUkkXSRqT6jhU0u2S7pF0laStU/lySedJugc4AegALk9tTazw1wacHMowA/huROwJrAE+UnE8reCtwPci4u3A87z+bf25iPhPwIXAd1LZBUBXROwNXA50pvIDgYV96t0yIt6Z6vtxKvs8cFNE7AscDHxD0lbAPwHnp/07gB5gLvBwRLwzIj6T3r8A+M9N+r3L0NS+jIjrgIuAb0fEwXXaexdZ8tgDeEt6L8CFEfGeiNgLmAgc2feNEbER6AbeMfhftzqS3g4cBxyYPjevkvX/tcBXgK8DP4mI+9Nb9gVOJ+ur3YC/kzQZ+ALw/ojYh+zzdWZNM89ExD4R8ZO07cT0eVxX/m84MCeH5ns0Ihan5YXA9ApjaRWPR8Tv0vJPgPem5StqXg9Iywfw+umOy2r23QlY1afeKwAi4jZgG0mTgEOBuZIWA7cAE4BpwO3A5ySdRTafTH//+Z6mhQ7t6yirL/tzV0T0pD/0i3n983ywpDsl3Ud2JLJnP+9v9f4cyEzg3cDd6fM0kyxBngN8gOxLxtdr9r8rIh6JiFfJ/h3eC+xPlix+l+qYBexS856flv5bDNKwPdxrYX+uWX6V7FvVBl5PxBOGPKLq9R1ME3XKNzXgZh35vqtXr4CPRMTSPtuWSLoT+BBwnaT/DjxSp50Jqa1WVVZf9qfv53mcpAnA94COiHhc0j8PUF+r9+dARHbkdfZfFEo7AVsD48l+vxfTpv4+j/Mj4oR+2nixn/LK+chhaCwn+wYCcEyFcVRlmqTeb7P/APw2LR9X83p7Wv49cHxaPpHsvDXAEqC9T73HAUh6L9lpleeAXwOn15wbf1d6fQvwSER0AtcAewNrgTf2qXN34H5aV1l9uTl6E8HqdP58oM90q/fnQG4EjpH0ZgBJ20naBfgB8EWyU3Xn1ey/r6Rd07WG48j+be4ADqy5DrSVpN37aa/e57EyTg5D45tkF/wWkU3lO9osBU6TtATYluwuFoBtJd0LnAF8KpWdDpySyk9K2wCuB97Xp96XU59eBJyayv4X2Te6eyU9kNYBjgXuT4f2ewGXRsQzZIf799dckD4Y+I9m/NIlKasvC4uINcAPyf7o/xq4u95+knYA1kXEk4Ntq0oR8SDZ9YIbUh/OJzsttD4i/o3shob3SDokveVusms+S4BHgV+kO+BOBq5IddwOvK2fJi8BLmqVC9KePsNKJWk68Mt04bK2fDnZaYnCc95L+gXw2YhY1swY+7RxG3BURDxbVhuDNQz78lPA8xFxcVlttApJBwGfjojchfnhykcONpzMJbuYWgpJU4BvtWJiKEGpfZmsAbpKbsNK4iMHMzPL8ZGDmZnlODmYmVmOk4OZmeU4OZiVRH85p9Z1aQS32bDgEdJmQyAijqg6BrPN4SMHs4IGmBV1prIZYO9TNiPsG+q8d3mahA1JH00ze/5B0mWS3ijpUUnj0/ZtatfNquDkYLZ5+s6KeibZyNbj0qyo44CP9/dmSXuSjbo9JCLeAZwREWvJJgn8UNrteODnEbG+rF/CbFOcHMw2T99ZUWeSzcT7x1TWxcBTUxwCXNU7mjki/pTKfwSckpZPAf61qVGbbSYnB7PN03fU6JqmVJolnOlpGoaxNc8IMKuEk4PZ5uk7K+oCsj/qvbOcngTcOsD7bwL+XtL2kM30WbPtUrLnL/iowSrn5GC2efrOivptstNAV6UH32wkmyW2roh4APgqcKukPwDfqtl8earzinrvNRtKnlvJrKD+ZkVtYv3HkM0Ie1IZ9ZttDo9zMGsBki4ADgc8HsJago8czMwsx9cczMwsx8nBzMxynBzMzCzHycHMzHKcHMzMLOf/A2izsVCNEKRhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rwl6xZvwu-hr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}